{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>N50_Adj Close</th>\n",
       "      <th>NB_Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237.000000</td>\n",
       "      <td>239.964996</td>\n",
       "      <td>235.039993</td>\n",
       "      <td>223.205643</td>\n",
       "      <td>5398390.0</td>\n",
       "      <td>6157.600098</td>\n",
       "      <td>11855.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238.649994</td>\n",
       "      <td>238.800003</td>\n",
       "      <td>233.300003</td>\n",
       "      <td>219.008545</td>\n",
       "      <td>8284130.0</td>\n",
       "      <td>6146.350098</td>\n",
       "      <td>11564.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234.970001</td>\n",
       "      <td>234.970001</td>\n",
       "      <td>229.750000</td>\n",
       "      <td>215.521133</td>\n",
       "      <td>7825920.0</td>\n",
       "      <td>6079.799805</td>\n",
       "      <td>11305.450195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231.600006</td>\n",
       "      <td>234.264999</td>\n",
       "      <td>230.899994</td>\n",
       "      <td>217.346527</td>\n",
       "      <td>5435090.0</td>\n",
       "      <td>6048.250000</td>\n",
       "      <td>11186.799805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232.619995</td>\n",
       "      <td>232.619995</td>\n",
       "      <td>226.100006</td>\n",
       "      <td>211.902969</td>\n",
       "      <td>7948010.0</td>\n",
       "      <td>5904.600098</td>\n",
       "      <td>11053.349609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low   Adj Close     Volume  N50_Adj Close  \\\n",
       "0  237.000000  239.964996  235.039993  223.205643  5398390.0    6157.600098   \n",
       "1  238.649994  238.800003  233.300003  219.008545  8284130.0    6146.350098   \n",
       "2  234.970001  234.970001  229.750000  215.521133  7825920.0    6079.799805   \n",
       "3  231.600006  234.264999  230.899994  217.346527  5435090.0    6048.250000   \n",
       "4  232.619995  232.619995  226.100006  211.902969  7948010.0    5904.600098   \n",
       "\n",
       "   NB_Adj Close  \n",
       "0  11855.750000  \n",
       "1  11564.049805  \n",
       "2  11305.450195  \n",
       "3  11186.799805  \n",
       "4  11053.349609  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PREPARATION ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Loading Datasets\n",
    "\n",
    "hdfc = pd.read_csv (r'C:\\Users\\MOHIT.K\\Desktop\\STock Market Prediction Literature\\Stock trend Prediction\\HDFC_NSE.csv')\n",
    "n_50 = pd.read_csv (r'C:\\Users\\MOHIT.K\\Desktop\\STock Market Prediction Literature\\Stock trend Prediction\\NIFTY_50.csv')\n",
    "n_bank = pd.read_csv (r'C:\\Users\\MOHIT.K\\Desktop\\STock Market Prediction Literature\\Stock trend Prediction\\NIFTY_BANK.csv')\n",
    "\n",
    "#Renaming Columns and Dropping Date, Volume and Close Columns \n",
    "\n",
    "n_50.rename(columns = {'Date':'N50_Date', 'Open':'N50_Open', 'High':'N50_High', 'Low':'N50_Low', 'Close':'N50_Close', 'Adj Close': 'N50_Adj Close', 'Volume': 'N50_Volume'}, inplace = True)\n",
    "n_bank.rename(columns = {'Date':'NB_Date','Open':'NB_Open', 'High':'NB_High', 'Low':'NB_Low', 'Close':'NB_Close', 'Adj Close': 'NB_Adj Close', 'Volume': 'NB_Volume'}, inplace = True)\n",
    "\n",
    "HDFC = hdfc.drop(['Date', 'Close'], axis = 1)\n",
    "Nifty_50 = n_50.drop(['N50_Date', 'N50_Volume', 'N50_Close', 'N50_Open', 'N50_High', 'N50_Low'], axis=1)\n",
    "Nifty_Bank = n_bank.drop(['NB_Date', 'NB_Volume', 'NB_Close', 'NB_Open', 'NB_High', 'NB_Low'], axis=1)\n",
    "\n",
    "#Merging the datasets and deleting rows with any null values to create Project Dataset\n",
    "\n",
    "HDFC_Working = pd.concat([HDFC, Nifty_50, Nifty_Bank], axis = 1)\n",
    "HDFC_Working = HDFC_Working.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "HDFC_Working.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Adding a Direction column for classification\n",
    "\n",
    "HDFC_Working_C = HDFC_Working.copy()\n",
    "\n",
    "HDFC_Working_C[\"Sign\"] =  HDFC_Working_C[\"Adj Close\"].diff(1)\n",
    "HDFC_Working_C.iat[0, 7] = 0\n",
    "\n",
    "HDFC_Working_C[\"Direction\"] = \"\"\n",
    "\n",
    "i = 0\n",
    "for j in range(2217):\n",
    "\n",
    "    if(HDFC_Working_C.iat[i, 7] >= 0):\n",
    "        HDFC_Working_C.iat[i, 8] = 1\n",
    "    else:\n",
    "        HDFC_Working_C.iat[i, 8]= 0\n",
    "    i = i + 1\n",
    "\n",
    "HDFC_Working_C = HDFC_Working_C.drop(['Sign'], axis = 1)\n",
    "\n",
    "#Creating Train and Test sets for Regression\n",
    "\n",
    "HDFC_Working_Train = HDFC_Working[ : 1774]\n",
    "HDFC_Working_Test = HDFC_Working[1774 : ]\n",
    "\n",
    "#Creating Train and Test sets for Classifiaction\n",
    "\n",
    "HDFC_Working_C_train=HDFC_Working_C[ : 1774]\n",
    "HDFC_Working_C_test=HDFC_Working_C[1774 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [3.31192413 1.5844025  2.13296101 2.2205876  2.17349932 2.68644882\n",
      " 3.07673462 3.61978007 3.78477728 4.8097414 ]\n",
      "Mean: 2.9400856751874604\n",
      "Standard deviation: 0.9212507010126924\n"
     ]
    }
   ],
   "source": [
    "###Linear Regressor###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "HDFC_Targets = HDFC_Working_Train[\"Adj Close\"].copy()\n",
    "HDFC_Linear =  HDFC_Working_Train.drop(\"Adj Close\", axis=1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "#Cross Validation\n",
    "\n",
    "scores = cross_val_score(lin_reg, HDFC_Linear, HDFC_Targets, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 3.20549442  9.59617263  6.74705175  4.58211489 24.83026496 47.80976861\n",
      " 37.39001358 45.32447671  9.9676972  25.17077773]\n",
      "Mean: 21.462383248633106\n",
      "Standard deviation: 16.27913276998717\n"
     ]
    }
   ],
   "source": [
    "###Decision Tree Regressor##$\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "HDFC_Targets = HDFC_Working_Train[\"Adj Close\"].copy()\n",
    "HDFC_DT =  HDFC_Working_Train.drop(\"Adj Close\", axis=1)\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "#Cross Validation\n",
    "\n",
    "scores = cross_val_score(tree_reg, HDFC_DT, HDFC_Targets, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [ 3.64397953  4.83167232  5.78585475  3.49308556 11.58060523 27.25211368\n",
      " 47.4246444  35.49944333  7.84587994 26.93143774]\n",
      "Mean: 17.428871649012443\n",
      "Standard deviation: 14.891613069630766\n"
     ]
    }
   ],
   "source": [
    "###Random Forest Regressor###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "HDFC_Targets = HDFC_Working_Train[\"Adj Close\"].copy()\n",
    "HDFC_RF =  HDFC_Working_Train.drop(\"Adj Close\", axis=1)\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "#Cross Validation\n",
    "\n",
    "scores = cross_val_score(forest_reg, HDFC_RF, HDFC_Targets, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(rmse_scores)\n",
    "\n",
    "#Though the scores here are better than Decision Tree, they are worse than Linear Regression. \n",
    "#Is it so because the Random Forest Regressor is still overfitting the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [181.22790083 180.8573404  146.31921916  99.38778745 115.82269603\n",
      "  74.81706132 155.21626852 427.72404991 579.343703   694.26490977]\n",
      "Mean: 265.4980936377505\n",
      "Standard deviation: 208.72065833396718\n"
     ]
    }
   ],
   "source": [
    "### SVR ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "HDFC_Targets = HDFC_Working_Train[\"Adj Close\"].copy()\n",
    "HDFC_SVR =  HDFC_Working_Train.drop(\"Adj Close\", axis=1)\n",
    "\n",
    "svm_reg = SVR()\n",
    "\n",
    "\n",
    "#Cross Validation\n",
    "\n",
    "scores = cross_val_score(svm_reg, HDFC_SVR, HDFC_Targets, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(rmse_scores)\n",
    "\n",
    "#No idea why SVR is overfitting the data so badly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVR with GRID SEARCH ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "HDFC_Targets = HDFC_Working_Train[\"Adj Close\"].copy()\n",
    "HDFC_SVR =  HDFC_Working_Train.drop(\"Adj Close\", axis=1)\n",
    "\n",
    "svm_reg = SVR()\n",
    "\n",
    "#Grid Search\n",
    "\n",
    "param_grid ={'C': [0.1, 1],  \n",
    "              'gamma': [1, 0.1], \n",
    "              'gamma':['scale', 'auto'],\n",
    "              'kernel': ['linear', 'rbf']}\n",
    "\n",
    "grid_search = GridSearchCV(svm_reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(HDFC_SVR, HDFC_Targets)\n",
    "\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0, 1], dtype=object),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-25b437415782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msgd_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msgd_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHDFC_BinaryClass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHDFC_Binary_Targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\NLP\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    730\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NLP\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[1;32m--> 570\u001b[1;33m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         if (self.tol is not None and self.tol > -np.inf\n",
      "\u001b[1;32m~\\Desktop\\NLP\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[0m_check_partial_fit_first_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NLP\\Anaconda\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36m_check_partial_fit_first_call\u001b[1;34m(clf, classes)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;31m# This is the first call to partial_fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\NLP\\Anaconda\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0, 1], dtype=object),)"
     ]
    }
   ],
   "source": [
    "### SGD Classifier ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "HDFC_Binary_Targets = HDFC_Working_C_train[\"Direction\"].copy()\n",
    "HDFC_BinaryClass = HDFC_Working_C_train.drop(\"Direction\", axis = 1)\n",
    "\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(HDFC_BinaryClass, HDFC_Binary_Targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
